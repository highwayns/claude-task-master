# Task Master AI - Docker Environment Configuration
# Copy this file to .env and fill in your API keys

# =============================================================================
# AI Provider API Keys (at least one required)
# =============================================================================

# Anthropic Claude (Recommended)
ANTHROPIC_API_KEY=

# Perplexity (Recommended for research features)
PERPLEXITY_API_KEY=

# OpenAI GPT Models
OPENAI_API_KEY=

# Google Gemini
GOOGLE_API_KEY=

# xAI Grok
XAI_API_KEY=

# OpenRouter (Multiple providers)
OPENROUTER_API_KEY=

# Mistral AI
MISTRAL_API_KEY=

# Azure OpenAI
AZURE_OPENAI_API_KEY=

# Ollama (Local models)
OLLAMA_API_KEY=

# =============================================================================
# Application Configuration
# =============================================================================

# Node environment
NODE_ENV=production

# Application port (if applicable)
PORT=3000

# =============================================================================
# Docker-Specific Configuration
# =============================================================================

# Docker registry for pushing/pulling images
# REGISTRY=your-registry.com

# Container timezone
# TZ=America/New_York

# =============================================================================
# Telemetry & Analytics (Optional)
# =============================================================================

# Set to 'false' to disable telemetry
# ENABLE_TELEMETRY=true

# =============================================================================
# Advanced Configuration (Optional)
# =============================================================================

# Custom model configuration
# TM_MODEL_MAIN=claude-3-5-sonnet-20241022
# TM_MODEL_RESEARCH=perplexity-llama-3.1-sonar-large-128k-online
# TM_MODEL_FALLBACK=gpt-4o-mini

# Debug mode
# DEBUG=task-master:*

# Log level (error, warn, info, debug)
# LOG_LEVEL=info
